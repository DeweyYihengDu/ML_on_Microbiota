{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Optimal Feature Selection and Evaluation\n",
    "\n",
    "This notebook demonstrates the process of identifying the best number of features for model performance. It includes:\n",
    "\n",
    "- Data preprocessing and cleaning\n",
    "- Feature selection and transformation\n",
    "- Model training with various classifiers\n",
    "- Evaluation of model performance to determine the optimal feature set\n",
    "\n",
    "The goal is to achieve the highest accuracy in predicting antibiotic combinations by selecting the appropriate number of top features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprt libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to map antibiotic concentration to categories\n",
    "def map_concentration(value):\n",
    "    if pd.isna(value):\n",
    "        return \"unknown\"\n",
    "    elif value == 0:\n",
    "        return \"none\"\n",
    "    elif value in [5, 10]:\n",
    "        return \"low\"\n",
    "    elif value in [50, 100]:\n",
    "        return \"high\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_and_preprocess_data(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    antibiotics = ['amoxicillin', 'oxytetracycline_dihydrate', 'sulfadiazine', 'trimethoprim', 'tylosin_tartrate', 'ciprofloxacin']\n",
    "    for antibiotic in antibiotics:\n",
    "        df[antibiotic] = df[antibiotic].apply(map_concentration)\n",
    "    df['antibiotic_combination'] = df[antibiotics].apply(lambda row: '_'.join(row), axis=1)\n",
    "    return df.dropna()\n",
    "\n",
    "# Evaluate models and select the best number of features\n",
    "def evaluate_models(df_cleaned, feature_columns, target_column):\n",
    "    X = pd.concat([df_cleaned[feature_columns], df_cleaned[['Isolation_source', 'Group']]], axis=1)\n",
    "    X = pd.get_dummies(X)\n",
    "    y = df_cleaned[target_column].astype('category').cat.codes\n",
    "    \n",
    "    models = {\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "        \"SVM\": SVC(random_state=42),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(random_state=42)\n",
    "    }\n",
    "    \n",
    "    accuracy_scores = {}\n",
    "    for k in range(10, 101, 10):\n",
    "        selector = SelectKBest(chi2, k=k)\n",
    "        X_selected = selector.fit_transform(X, y)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if k not in accuracy_scores or acc > accuracy_scores[k]:\n",
    "                accuracy_scores[k] = acc\n",
    "    \n",
    "    return accuracy_scores\n",
    "\n",
    "# Main execution\n",
    "file_path = '../matrix/otu_merged_data.csv'\n",
    "df_cleaned = load_and_preprocess_data(file_path)\n",
    "feature_columns = [col for col in df_cleaned.columns if col.startswith('o__')]\n",
    "accuracy_scores = evaluate_models(df_cleaned, feature_columns, 'antibiotic_combination')\n",
    "\n",
    "# Plot the accuracy scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(accuracy_scores.keys(), accuracy_scores.values(), color='lightblue')\n",
    "plt.title('Model Accuracy by Number of Features')\n",
    "plt.xlabel('Number of Top Features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(range(10, 101, 10))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = max(accuracy_scores, key=accuracy_scores.get)\n",
    "best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw the confusion matrix for the given input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Read the data from the CSV file\n",
    "df = pd.read_csv('../matrix/otu_merged_data.csv')\n",
    "\n",
    "# Function to map concentration values to categories\n",
    "def map_concentration(value):\n",
    "    if pd.isna(value):\n",
    "        return \"unknown\"\n",
    "    elif value == 0:\n",
    "        return \"none\"\n",
    "    elif value in [5, 10]:\n",
    "        return \"low\"\n",
    "    elif value in [50, 100]:\n",
    "        return \"high\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Apply concentration mapping to antibiotic columns\n",
    "antibiotics = ['amoxicillin', 'oxytetracycline_dihydrate', 'sulfadiazine', 'trimethoprim', 'tylosin_tartrate', 'ciprofloxacin']\n",
    "for antibiotic in antibiotics:\n",
    "    df[antibiotic] = df[antibiotic].apply(map_concentration)\n",
    "\n",
    "# Function to map antibiotic concentrations to set names\n",
    "def map_to_set(row):\n",
    "    if all(value == 'unknown' for value in row):\n",
    "        return 'Unknown'\n",
    "    mapping = {\n",
    "        'high_high_high_high_high_high': 'Set 1',\n",
    "        'high_high_high_none_none_none': 'Set 2',\n",
    "        'high_none_none_none_none_none': 'Set 3',\n",
    "        'low_low_low_low_low_low': 'Set 4',\n",
    "        'low_low_low_none_none_none': 'Set 5',\n",
    "        'low_none_none_none_none_none': 'Set 6',\n",
    "        'none_none_none_none_none_none': 'Control'\n",
    "    }\n",
    "    key = '_'.join(row)\n",
    "    return mapping.get(key, 'Other')\n",
    "\n",
    "# Apply set mapping to create a new 'set_name' column\n",
    "df['set_name'] = df[antibiotics].apply(map_to_set, axis=1)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Select feature columns starting with 'o__'\n",
    "feature_columns = [col for col in df_cleaned.columns if col.startswith('o__')]\n",
    "X = df_cleaned[feature_columns]\n",
    "\n",
    "# Concatenate feature columns with 'Isolation_source' and 'Group' columns\n",
    "X = pd.concat([X, df_cleaned[['Isolation_source', 'Group']]], axis=1)\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "X = pd.get_dummies(X, columns=['Isolation_source', 'Group'])\n",
    "\n",
    "# Target variable\n",
    "y = df_cleaned['set_name']\n",
    "\n",
    "# Encode target variable using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Select k best features using chi-squared test\n",
    "best_k = best_k # get from previous example\n",
    "selector = SelectKBest(chi2, k=best_k)\n",
    "X_selected = selector.fit_transform(X, y_encoded)\n",
    "\n",
    "# Scale the selected features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_selected)\n",
    "\n",
    "# Oversample the data to balance the classes\n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_scaled, y_encoded)\n",
    "X_balanced, y_balanced = X_resampled, y_resampled\n",
    "\n",
    "# Define the models to be evaluated\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression()\n",
    "}\n",
    "\n",
    "# Define the parameter grids for grid search\n",
    "param_grids = {\n",
    "    \"Random Forest\": {'n_estimators': [100, 200], 'max_depth': [10, 20]},\n",
    "    \"SVM\": {'C': [1, 10], 'kernel': ['rbf', 'linear']},\n",
    "    \"Decision Tree\": {'max_depth': [5, 10]},\n",
    "    \"Logistic Regression\": {'C': [1, 10]}\n",
    "}\n",
    "\n",
    "# Create subplots for each model\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 12))\n",
    "axes = axes.flatten() \n",
    "\n",
    "# Perform grid search and cross-validation for each model\n",
    "for ax, (name, model) in zip(axes, models.items()):\n",
    "    grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='roc_auc_ovr')\n",
    "    grid_search.fit(X_balanced, y_balanced)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Make predictions using the best model\n",
    "    y_pred = cross_val_predict(best_model, X_balanced, y_balanced, cv=5)\n",
    "    y_balanced_labels = label_encoder.inverse_transform(y_balanced)\n",
    "    y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "    cm = confusion_matrix(y_balanced_labels, y_pred_labels, labels=label_encoder.classes_)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    annot_array = np.vectorize(lambda x, y: f'{x}\\n({y:.2%})')(cm, cm_normalized)\n",
    "    \n",
    "    sns.heatmap(cm_normalized, annot=annot_array, fmt=\"\", cmap='Blues', ax=ax)\n",
    "    ax.set_title(f'Normalized Confusion Matrix for {name}', fontsize=14)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "    ax.set_xticklabels(labels=label_encoder.classes_, rotation=45)\n",
    "    ax.set_yticklabels(labels=label_encoder.classes_, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrices.pdf', format='pdf', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw the ROC plot on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "best_k=40\n",
    "df = pd.read_csv('../matrix/otu_merged_data.csv') \n",
    "\n",
    "# Function to map concentration values to categories\n",
    "def map_concentration(value):\n",
    "    if pd.isna(value):\n",
    "        return \"unknown\"\n",
    "    elif value == 0:\n",
    "        return \"none\"\n",
    "    elif value in [5, 10]:\n",
    "        return \"low\"\n",
    "    elif value in [50, 100]:\n",
    "        return \"high\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "antibiotics = ['amoxicillin', 'oxytetracycline_dihydrate', 'sulfadiazine', 'trimethoprim', 'tylosin_tartrate', 'ciprofloxacin']\n",
    "for antibiotic in antibiotics:\n",
    "    df[antibiotic] = df[antibiotic].apply(map_concentration)\n",
    "\n",
    "# Function to map antibiotic concentrations to set names\n",
    "def map_to_set(row):\n",
    "    mapping = {\n",
    "        'high_high_high_high_high_high': 'Set 1',\n",
    "        'high_high_high_none_none_none': 'Set 2',\n",
    "        'high_none_none_none_none_none': 'Set 3',\n",
    "        'low_low_low_low_low_low': 'Set 4',\n",
    "        'low_low_low_none_none_none': 'Set 5',\n",
    "        'low_none_none_none_none_none': 'Set 6',\n",
    "        'none_none_none_none_none_none': 'Control'\n",
    "    }\n",
    "    key = '_'.join(row)\n",
    "    return mapping.get(key, 'Other')\n",
    "\n",
    "df['set_name'] = df[antibiotics].apply(map_to_set, axis=1)\n",
    "\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Selecting feature columns\n",
    "feature_columns = [col for col in df_cleaned.columns if col.startswith('o__')]\n",
    "X = df_cleaned[feature_columns]\n",
    "X = pd.concat([X, df_cleaned[['Isolation_source', 'Group']]], axis=1)\n",
    "X = pd.get_dummies(X, columns=['Isolation_source', 'Group'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(random_state=42, probability=True),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42)\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    \"Random Forest\": {'n_estimators': [100, 200], 'max_depth': [10, 20]},\n",
    "    \"SVM\": {'C': [1, 10], 'kernel': ['rbf', 'linear']},\n",
    "    \"Decision Tree\": {'max_depth': [5, 10]},\n",
    "    \"Logistic Regression\": {'C': [1, 10]}\n",
    "}\n",
    "\n",
    "sets = ['Set 1', 'Set 2', 'Set 3', 'Set 4', 'Set 5', 'Set 6', 'Control']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))\n",
    "axes = axes.ravel() \n",
    "\n",
    "# Loop through each set and create subplots\n",
    "for i, set_name in enumerate(['Set 1', 'Set 2', 'Set 3', 'Set 4', 'Set 5', 'Set 6']):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # Convert set names to binary labels\n",
    "    y_binary = df_cleaned['set_name'].apply(lambda x: 1 if x == set_name else 0)\n",
    "\n",
    "    # Feature selection using chi-square test\n",
    "    selector = SelectKBest(chi2, k=best_k)\n",
    "    X_selected = selector.fit_transform(X, y_binary)\n",
    "    X_scaled = scaler.fit_transform(X_selected)\n",
    "\n",
    "    # Resampling using RandomOverSampler\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_scaled, y_binary)\n",
    "\n",
    "    X_balanced, y_balanced = X_resampled, y_resampled\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3)\n",
    "    \n",
    "    \n",
    "    for name, model in models.items():\n",
    "        grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='roc_auc')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_probas = cross_val_predict(best_model, X_test, y_test, cv=5, method='predict_proba')\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_probas[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        ax.plot(fpr, tpr, label=f'{name} (area = {roc_auc:.2f})')\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title(f'ROC Curves for {set_name} vs Control')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
