{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose the best number of features for model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load the data\n",
    "file_path = '../matrix/otu_merged_data.csv' \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "def map_concentration(value):\n",
    "    if pd.isna(value):\n",
    "        return \"unknown\"  \n",
    "    elif value == 0:\n",
    "        return \"none\"\n",
    "    elif value in [5, 10]:\n",
    "        return \"low\"\n",
    "    elif value in [50, 100]:\n",
    "        return \"high\"\n",
    "    else:\n",
    "        return \"unknown\"  \n",
    "\n",
    "antibiotics = ['amoxicillin', 'oxytetracycline_dihydrate', 'sulfadiazine', 'trimethoprim', 'tylosin_tartrate', 'ciprofloxacin']\n",
    "for antibiotic in antibiotics:\n",
    "    df[antibiotic] = df[antibiotic].apply(map_concentration)\n",
    "\n",
    "df['antibiotic_combination'] = df[antibiotics].apply(lambda row: '_'.join(row), axis=1)\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "\n",
    "feature_columns = [col for col in df_cleaned.columns if col.startswith('o__')]\n",
    "X = df_cleaned[feature_columns]\n",
    "X = pd.concat([X, df_cleaned[['Isolation_source', 'Group']]], axis=1)\n",
    "X = pd.get_dummies(X, columns=['Isolation_source', 'Group'])\n",
    "\n",
    "y = df_cleaned['antibiotic_combination']\n",
    "y_encoded = y.astype('category').cat.codes\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42)\n",
    "}\n",
    "\n",
    "\n",
    "accuracy_scores = {}\n",
    "for k in range(10, 101, 10):\n",
    "    print(f\"Using top {k} features\")\n",
    "\n",
    "    # select the top k features\n",
    "    selector = SelectKBest(chi2, k=k)\n",
    "    X_selected = selector.fit_transform(X, y_encoded)\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    best_accuracy = 0\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Model: {name}, Accuracy: {acc:.4f}\")\n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "\n",
    "    accuracy_scores[k] = best_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "# plt.bar(accuracy_scores.keys(), accuracy_scores.values(), color='lightblue',width=5)\n",
    "max_value = max(accuracy_scores.values())\n",
    "max_key = [k for k, v in accuracy_scores.items() if v == max_value][0]\n",
    "\n",
    "for key, value in accuracy_scores.items():\n",
    "    if key == max_key:\n",
    "        plt.bar(key, value, color='lightblue', width=5, edgecolor='black', linewidth=0.5) \n",
    "    else:\n",
    "        plt.bar(key, value, color='lightblue', width=5)\n",
    "\n",
    "\n",
    "plt.axhline(y=1/7, color='red', linestyle='dashed', linewidth=2)\n",
    "plt.text(2, 1/7-0.01, r'$\\frac{1}{7}$', verticalalignment='bottom', horizontalalignment='right', color='red', fontsize=16)\n",
    "plt.title('Best Accuracy by Number of Features')\n",
    "plt.xlabel('Number of Top Features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(range(10, 101, 10))\n",
    "plt.show()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = max(accuracy_scores, key=accuracy_scores.get)\n",
    "best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw the confusion matrix for the given input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "df = pd.read_csv('../matrix/otu_merged_data.csv')\n",
    "\n",
    "def map_concentration(value):\n",
    "    if pd.isna(value):\n",
    "        return \"unknown\"\n",
    "    elif value == 0:\n",
    "        return \"none\"\n",
    "    elif value in [5, 10]:\n",
    "        return \"low\"\n",
    "    elif value in [50, 100]:\n",
    "        return \"high\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "antibiotics = ['amoxicillin', 'oxytetracycline_dihydrate', 'sulfadiazine', 'trimethoprim', 'tylosin_tartrate', 'ciprofloxacin']\n",
    "for antibiotic in antibiotics:\n",
    "    df[antibiotic] = df[antibiotic].apply(map_concentration)\n",
    "\n",
    "def map_to_set(row):\n",
    "    if all(value == 'unknown' for value in row):\n",
    "        return 'Unknown'\n",
    "    mapping = {\n",
    "        'high_high_high_high_high_high': 'Set 1',\n",
    "        'high_high_high_none_none_none': 'Set 2',\n",
    "        'high_none_none_none_none_none': 'Set 3',\n",
    "        'low_low_low_low_low_low': 'Set 4',\n",
    "        'low_low_low_none_none_none': 'Set 5',\n",
    "        'low_none_none_none_none_none': 'Set 6',\n",
    "        'none_none_none_none_none_none': 'Control'\n",
    "    }\n",
    "    key = '_'.join(row)\n",
    "    return mapping.get(key, 'Other')\n",
    "\n",
    "df['set_name'] = df[antibiotics].apply(map_to_set, axis=1)\n",
    "\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "feature_columns = [col for col in df_cleaned.columns if col.startswith('o__')]\n",
    "X = df_cleaned[feature_columns]\n",
    "X = pd.concat([X, df_cleaned[['Isolation_source', 'Group']]], axis=1)\n",
    "X = pd.get_dummies(X, columns=['Isolation_source', 'Group'])\n",
    "\n",
    "y = df_cleaned['set_name']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "best_k = best_k # get from previous example\n",
    "selector = SelectKBest(chi2, k=best_k)\n",
    "X_selected = selector.fit_transform(X, y_encoded)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_selected)\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_scaled, y_encoded)\n",
    "X_balanced, y_balanced = X_resampled, y_resampled\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    \"Random Forest\": {'n_estimators': [100, 200], 'max_depth': [10, 20]},\n",
    "    \"SVM\": {'C': [1, 10], 'kernel': ['rbf', 'linear']},\n",
    "    \"Decision Tree\": {'max_depth': [5, 10]},\n",
    "    \"Logistic Regression\": {'C': [1, 10]}\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 12))\n",
    "axes = axes.flatten() \n",
    "\n",
    "for ax, (name, model) in zip(axes, models.items()):\n",
    "    grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='roc_auc_ovr')\n",
    "    grid_search.fit(X_balanced, y_balanced)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    y_pred = cross_val_predict(best_model, X_balanced, y_balanced, cv=5)\n",
    "    y_balanced_labels = label_encoder.inverse_transform(y_balanced)\n",
    "    y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "    cm = confusion_matrix(y_balanced_labels, y_pred_labels, labels=label_encoder.classes_)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    annot_array = np.vectorize(lambda x, y: f'{x}\\n({y:.2%})')(cm, cm_normalized)\n",
    "    \n",
    "    sns.heatmap(cm_normalized, annot=annot_array, fmt=\"\", cmap='Blues', ax=ax)\n",
    "    ax.set_title(f'Normalized Confusion Matrix for {name}', fontsize=14)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "    ax.set_xticklabels(labels=label_encoder.classes_, rotation=45)\n",
    "    ax.set_yticklabels(labels=label_encoder.classes_, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrices.pdf', format='pdf', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw the ROC plot on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "best_k=40\n",
    "df = pd.read_csv('../matrix/otu_merged_data.csv') \n",
    "\n",
    "def map_concentration(value):\n",
    "    if pd.isna(value):\n",
    "        return \"unknown\"\n",
    "    elif value == 0:\n",
    "        return \"none\"\n",
    "    elif value in [5, 10]:\n",
    "        return \"low\"\n",
    "    elif value in [50, 100]:\n",
    "        return \"high\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "antibiotics = ['amoxicillin', 'oxytetracycline_dihydrate', 'sulfadiazine', 'trimethoprim', 'tylosin_tartrate', 'ciprofloxacin']\n",
    "for antibiotic in antibiotics:\n",
    "    df[antibiotic] = df[antibiotic].apply(map_concentration)\n",
    "\n",
    "def map_to_set(row):\n",
    "    mapping = {\n",
    "        'high_high_high_high_high_high': 'Set 1',\n",
    "        'high_high_high_none_none_none': 'Set 2',\n",
    "        'high_none_none_none_none_none': 'Set 3',\n",
    "        'low_low_low_low_low_low': 'Set 4',\n",
    "        'low_low_low_none_none_none': 'Set 5',\n",
    "        'low_none_none_none_none_none': 'Set 6',\n",
    "        'none_none_none_none_none_none': 'Control'\n",
    "    }\n",
    "    key = '_'.join(row)\n",
    "    return mapping.get(key, 'Other')\n",
    "\n",
    "df['set_name'] = df[antibiotics].apply(map_to_set, axis=1)\n",
    "\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "\n",
    "feature_columns = [col for col in df_cleaned.columns if col.startswith('o__')]\n",
    "X = df_cleaned[feature_columns]\n",
    "X = pd.concat([X, df_cleaned[['Isolation_source', 'Group']]], axis=1)\n",
    "X = pd.get_dummies(X, columns=['Isolation_source', 'Group'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(random_state=42, probability=True),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42)\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    \"Random Forest\": {'n_estimators': [100, 200], 'max_depth': [10, 20]},\n",
    "    \"SVM\": {'C': [1, 10], 'kernel': ['rbf', 'linear']},\n",
    "    \"Decision Tree\": {'max_depth': [5, 10]},\n",
    "    \"Logistic Regression\": {'C': [1, 10]}\n",
    "}\n",
    "\n",
    "\n",
    "sets = ['Set 1', 'Set 2', 'Set 3', 'Set 4', 'Set 5', 'Set 6', 'Control']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))\n",
    "axes = axes.ravel() \n",
    "\n",
    "for i, set_name in enumerate(['Set 1', 'Set 2', 'Set 3', 'Set 4', 'Set 5', 'Set 6']):\n",
    "    ax = axes[i]\n",
    "\n",
    "\n",
    "    y_binary = df_cleaned['set_name'].apply(lambda x: 1 if x == set_name else 0)\n",
    "\n",
    "    selector = SelectKBest(chi2, k=best_k)\n",
    "    X_selected = selector.fit_transform(X, y_binary)\n",
    "    X_scaled = scaler.fit_transform(X_selected)\n",
    "\n",
    "\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_scaled, y_binary)\n",
    "    # X_balanced, y_balanced = rus.fit_resample(X_resampled, y_resampled)\n",
    "    X_balanced, y_balanced = X_resampled, y_resampled\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3)\n",
    "    \n",
    "    \n",
    "    for name, model in models.items():\n",
    "        grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='roc_auc')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_probas = cross_val_predict(best_model, X_test, y_test, cv=5, method='predict_proba')\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_probas[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        ax.plot(fpr, tpr, label=f'{name} (area = {roc_auc:.2f})')\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title(f'ROC Curves for {set_name} vs Control')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
